{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Toy Datasets and Best Response\n",
    "This notebook provides the code to visualise 2D toy datasets from the /data/ directory and to visualise the impact of the best response on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install matplotlib\n",
    "! pip install ipympl\n",
    "! pip install imageio[ffmpeg]\n",
    "! pip install numpy\n",
    "#! pip install pandas\n",
    "#! pip install torch\n",
    "#! pip install \"numpy<2\"\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow relative importing from Clf_Learner module\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/boyan/project/strategic_classification_git/strategic_classification_framework'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/5g/x_qpm0ss6zngd7rf57nlqlbc0000gn/T/ipykernel_21434/3270815159.py\", line 1, in <module>\n",
      "    from Clf_Learner.tools.dataset_building_tools import get_dataset\n",
      "  File \"/Users/boyan/project/strategic_classification_git/strategic_classification_framework/Clf_Learner/tools/dataset_building_tools.py\", line 1, in <module>\n",
      "    from ..datasets import CSVDataset, CSV_DATASET_DICT\n",
      "  File \"/Users/boyan/project/strategic_classification_git/strategic_classification_framework/Clf_Learner/datasets/__init__.py\", line 1, in <module>\n",
      "    from .csv_dataset import CSVDataset\n",
      "  File \"/Users/boyan/project/strategic_classification_git/strategic_classification_framework/Clf_Learner/datasets/csv_dataset.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/boyan/anaconda3/envs/python312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from Clf_Learner.tools.dataset_building_tools import get_dataset\n",
    "from Clf_Learner.interfaces.base_dataset import BaseDataset\n",
    "from torch import Tensor\n",
    "\n",
    "def get_data(data_address, target_index=-1) -> tuple[Tensor, Tensor, BaseDataset|None]:\n",
    "    dataset = get_dataset(data_address, target_index)\n",
    "\n",
    "    X, y = Tensor([]), Tensor([])\n",
    "    if dataset is not None:\n",
    "        X, y = dataset.get_all_vals()\n",
    "\n",
    "    return X, y, dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Data Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_data2D(X, y):\n",
    "    \"\"\"Visualise 2D Dataset\"\"\"\n",
    "    assert X.size(1) == 2\n",
    "    if not X.size(1) == 2:\n",
    "        return\n",
    "    \n",
    "    Xpos = X[y == 1]\n",
    "    Xneg = X[y == -1]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(Xpos[:, 0], Xpos[:, 1], marker='+', color='blue')\n",
    "    ax.scatter(Xneg[:, 0], Xneg[:, 1], marker='_', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "MAX_NUM_FRAMES = 50\n",
    "\n",
    "def visualize_seperator2D(model, X, y, x_lim=None, z_lim=None, no_lim=False,\n",
    "                          animate=False, store=False, interval=300, fps=5):\n",
    "    \"\"\"\n",
    "    X: tensor (F, N, 2) if animate else (N,2)\n",
    "    y: tensor (N,) or (N,1) with labels in {1, -1}\n",
    "    \"\"\"\n",
    "    assert X.size(-1) == 2, \"Error: Visualisation can only be performed for 2D data\"\n",
    "    assert model.x_dim == 2, \"Error: Visualisation can only be performed for models trained on 2D data\"\n",
    "    assert hasattr(model, \"get_boundary_vals\"), \"Error: Visualisation requires model has 'get_boundary_vals' function defined\"\n",
    "    assert x_lim is None or (isinstance(x_lim, list|tuple) and len(x_lim)==2)\n",
    "    assert z_lim is None or (isinstance(z_lim, list|tuple) and len(z_lim)==2)\n",
    "\n",
    "    # Convert to Numpy for efficiency\n",
    "    X = X.detach().cpu().numpy()\n",
    "    if animate:\n",
    "        assert len(X.shape) == 3, \"Error: For animate=True, X must be (F,N,2)\"\n",
    "        F, N, D = X.shape\n",
    "        # downsample frames if needed\n",
    "        if F > MAX_NUM_FRAMES:\n",
    "            idx = torch.linspace(0, F-1, steps=MAX_NUM_FRAMES, dtype=torch.long).tolist()\n",
    "            if idx[-1] != F-1: idx.append(F-1)\n",
    "            X = X[idx]\n",
    "        frames = X.shape[0]\n",
    "    else:\n",
    "        assert len(X.shape) == 2, \"Error: For animate=False, X must be (N,2)\"\n",
    "        frames = 1\n",
    "\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    # compute global limits across all frames\n",
    "    flat = X.reshape(-1,2)\n",
    "    x_low0, z_low0 = flat.min(axis=0).tolist()\n",
    "    x_high0, z_high0 = flat.max(axis=0).tolist()\n",
    "    x_low, x_high = (x_lim if x_lim is not None else (x_low0, x_high0))\n",
    "    z_low, z_high = (z_lim if z_lim is not None else (z_low0, z_high0))\n",
    "\n",
    "    # --- Prepare figure & initial artists ---\n",
    "    fig, ax = plt.subplots()\n",
    "    if not no_lim:\n",
    "        ax.set_xlim(x_low, x_high)\n",
    "        ax.set_ylim(z_low, z_high)\n",
    "\n",
    "    first_frame = X[0] if animate else X\n",
    "    pos0 = first_frame[y == 1]\n",
    "    neg0 = first_frame[y == -1]\n",
    "\n",
    "    scat_pos = ax.scatter(pos0[:,0], pos0[:,1], marker='+', color='blue', label='Pos')\n",
    "    scat_neg = ax.scatter(neg0[:,0], neg0[:,1], marker='_', color='red', label='Neg')\n",
    "\n",
    "    # prepare range tensor for model boundary (use same device as X_torch)\n",
    "    range_t = torch.arange(int(x_low)-1, int(x_high)+1, 0.1)\n",
    "\n",
    "    # initial boundary lines (model.get_boundary_vals may return list or single tensor)\n",
    "    bcs = model.get_boundary_vals(range_t)\n",
    "    if not isinstance(bcs, list):\n",
    "        bcs = [bcs]\n",
    "    lines = []\n",
    "    for bc in bcs:\n",
    "        bc_np = bc.detach().cpu().numpy()\n",
    "        line, = ax.plot(bc_np[:,0], bc_np[:,1], linestyle='dashed', linewidth=2.0, alpha=0.75, color='green')\n",
    "        lines.append(line)\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    if not animate:\n",
    "        # Don't render in widget if not animating\n",
    "        plt.show()\n",
    "        return None\n",
    "\n",
    "    # --- Update function (updates existing artists) ---\n",
    "    def update(i):\n",
    "        frame = X[i]\n",
    "        pos = frame[y == 1]\n",
    "        neg = frame[y == -1]\n",
    "        if pos.size == 0:\n",
    "            scat_pos.set_offsets(np.empty((0,2)))\n",
    "        else:\n",
    "            scat_pos.set_offsets(pos)\n",
    "        if neg.size == 0:\n",
    "            scat_neg.set_offsets(np.empty((0,2)))\n",
    "        else:\n",
    "            scat_neg.set_offsets(neg)\n",
    "\n",
    "        # return artists (works when blit=False too, safe)\n",
    "        return [scat_pos, scat_neg] + lines\n",
    "\n",
    "    # --- Build & embed animation ---\n",
    "    ani = FuncAnimation(fig, update, frames=frames, interval=interval, blit=False, repeat=False)\n",
    "\n",
    "    # preferred: embed as JS animation in notebook (reliable in VS Code/Jupyter)\n",
    "    #ani_plot = ani.to_html5_video() # mpeg video\n",
    "    ani_plot = ani.to_jshtml() # interactive window\n",
    "    display(HTML(ani_plot))\n",
    "\n",
    "    # optional: save GIF if requested\n",
    "    if store:\n",
    "        gif_label = f\"{datetime.datetime.now():%Y-%m-%d_%H_%M}\"\n",
    "        gifname = f\"best_response_{gif_label}.gif\"\n",
    "        ani.save(f\"{gifname}\", dpi=150, writer=PillowWriter(fps=fps))\n",
    "        print(f\"Animation saved to {gifname}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting\n",
    "Here you specify the dataset you want to visualise and the subdirectory of ../results that contains the model specifications that you want to visualise the decision boundary of. \n",
    "Note: Datasets being visualised must be 2D datasets, and models whose decision boundaries are being visualised must have been trained on that dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_root = \"/Users/boyan/project/strategic_classification_git/strategic_classification_framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ball_half_ring_dataset_ball_rad_2_in_rad_3_out_rad_5\" \n",
    "#dataset_name = \"ball_half_ring_dataset_ball_rad_2_in_rad_3_out_rad_5\"\n",
    "#dataset_name = \"ball_half_ring_inverted_dataset_ball_rad_2_in_rad_3_out_rad_5\"\n",
    "#dataset_name = \"ball_ring_dataset_ball_rad_2_in_rad_3_out_rad_5\"\n",
    "#dataset_name = \"twin_moons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_dirname = \"toy_dataset/icnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardising Dataset\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m data_address = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m X, y, dataset = get_data(data_address, -\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m visualize_data2D(X, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mvisualize_data2D\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     13\u001b[39m fig = plt.figure()\n\u001b[32m     14\u001b[39m ax = fig.add_subplot(\u001b[32m111\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m ax.scatter(Xpos[:, \u001b[32m0\u001b[39m], Xpos[:, \u001b[32m1\u001b[39m], marker=\u001b[33m'\u001b[39m\u001b[33m+\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m ax.scatter(Xneg[:, \u001b[32m0\u001b[39m], Xneg[:, \u001b[32m1\u001b[39m], marker=\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/_api/deprecation.py:453\u001b[39m, in \u001b[36mmake_keyword_only.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > name_idx:\n\u001b[32m    448\u001b[39m     warn_deprecated(\n\u001b[32m    449\u001b[39m         since, message=\u001b[33m\"\u001b[39m\u001b[33mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[33m; the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    452\u001b[39m         name=name, obj_type=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[32m   1525\u001b[39m             ax,\n\u001b[32m   1526\u001b[39m             *\u001b[38;5;28mmap\u001b[39m(cbook.sanitize_sequence, args),\n\u001b[32m   1527\u001b[39m             **{k: cbook.sanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items()})\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/axes/_axes.py:4930\u001b[39m, in \u001b[36mAxes.scatter\u001b[39m\u001b[34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, colorizer, plotnonfinite, **kwargs)\u001b[39m\n\u001b[32m   4928\u001b[39m edgecolors = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   4929\u001b[39m \u001b[38;5;66;03m# Process **kwargs to handle aliases, conflicts with explicit kwargs:\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4930\u001b[39m x, y = \u001b[38;5;28mself\u001b[39m._process_unit_info([(\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m, x), (\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, y)], kwargs)\n\u001b[32m   4931\u001b[39m \u001b[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001b[39;00m\n\u001b[32m   4932\u001b[39m \u001b[38;5;66;03m# unless its argument is a masked array.\u001b[39;00m\n\u001b[32m   4933\u001b[39m x = np.ma.ravel(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/axes/_base.py:2663\u001b[39m, in \u001b[36m_AxesBase._process_unit_info\u001b[39m\u001b[34m(self, datasets, kwargs, convert)\u001b[39m\n\u001b[32m   2661\u001b[39m     \u001b[38;5;66;03m# Update from data if axis is already set but no unit is set yet.\u001b[39;00m\n\u001b[32m   2662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis.have_units():\n\u001b[32m-> \u001b[39m\u001b[32m2663\u001b[39m         axis.update_units(data)\n\u001b[32m   2664\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis_name, axis \u001b[38;5;129;01min\u001b[39;00m axis_map.items():\n\u001b[32m   2665\u001b[39m     \u001b[38;5;66;03m# Return if no axis is set.\u001b[39;00m\n\u001b[32m   2666\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/axis.py:1745\u001b[39m, in \u001b[36mAxis.update_units\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1739\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[33;03mIntrospect *data* for units converter and update the\u001b[39;00m\n\u001b[32m   1741\u001b[39m \u001b[33;03m``axis.get_converter`` instance if necessary. Return *True*\u001b[39;00m\n\u001b[32m   1742\u001b[39m \u001b[33;03mif *data* is registered for unit conversion.\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._converter_is_explicit:\n\u001b[32m-> \u001b[39m\u001b[32m1745\u001b[39m     converter = munits.registry.get_converter(data)\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1747\u001b[39m     converter = \u001b[38;5;28mself\u001b[39m._converter\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/units.py:167\u001b[39m, in \u001b[36mRegistry.get_converter\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the converter interface instance for *x*, or None.\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Unpack in case of e.g. Pandas or xarray object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m x = cbook._unpack_to_numpy(x)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np.ndarray):\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# In case x in a masked array, access the underlying data (only its\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# type matters).  If x is a regular ndarray, getdata() just returns\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# the array itself.\u001b[39;00m\n\u001b[32m    173\u001b[39m     x = np.ma.getdata(x).ravel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/matplotlib/cbook.py:2387\u001b[39m, in \u001b[36m_unpack_to_numpy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2381\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m xtmp\n\u001b[32m   2382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_jax_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_tensorflow_array(x):\n\u001b[32m   2383\u001b[39m     \u001b[38;5;66;03m# using np.asarray() instead of explicitly __array__(), as the latter is\u001b[39;00m\n\u001b[32m   2384\u001b[39m     \u001b[38;5;66;03m# only _one_ of many methods, and it's the last resort, see also\u001b[39;00m\n\u001b[32m   2385\u001b[39m     \u001b[38;5;66;03m# https://numpy.org/devdocs/user/basics.interoperability.html#using-arbitrary-objects-in-numpy\u001b[39;00m\n\u001b[32m   2386\u001b[39m     \u001b[38;5;66;03m# therefore, let arrays do better if they can\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2387\u001b[39m     xtmp = np.asarray(x)\n\u001b[32m   2389\u001b[39m     \u001b[38;5;66;03m# In case np.asarray method does not return a numpy array in future\u001b[39;00m\n\u001b[32m   2390\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xtmp, np.ndarray):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/python312/lib/python3.12/site-packages/torch/_tensor.py:1062\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy()\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "data_address = f\"{path_to_root}/data/{dataset_name}.csv\"\n",
    "X, y, dataset = get_data(data_address, -1)\n",
    "visualize_data2D(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Model Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clf_Learner.main import _load_args\n",
    "# Bad practise to import underscored function. But I'm gonna let it slide because this isn't getting released\n",
    "import Clf_Learner.tools.utils as utils\n",
    "utils.RESULTS_DIR = f\"{path_to_root}/results\"\n",
    "\n",
    "args = _load_args(f\"{utils.RESULTS_DIR}/{model_results_dirname}/commandline_args.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clf_Learner.tools.results_tools import fetch_model\n",
    "from Clf_Learner.tools.model_building_tools import get_model, get_model_spec\n",
    "\n",
    "if args.specs:\n",
    "    model_spec = get_model_spec(model_spec_name=args.specs[0])\n",
    "else:\n",
    "    model_spec = get_model_spec(br_name=args.best_response, cost_name=args.cost, loss_name=args.loss, model_type_name=args.model, utility_name=args.utility)\n",
    "\n",
    "init_args = {\"x_dim\": X.shape[1]}\n",
    "comp_args = args.args\n",
    "\n",
    "implicit = False # Implicit shouldn't matter for evaluating trained model\n",
    "\n",
    "model = get_model(model_spec, model_results_dirname, dataset, implicit, init_args, comp_args)\n",
    "model = fetch_model(model, model_results_dirname, dataset_name, model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_high, z_high = torch.max(X,0).values.tolist()\n",
    "x_low, z_low = torch.min(X,0).values.tolist()\n",
    "\n",
    "a = model.best_response(X, model, y=y).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Decision Boundary with Data with no Strategic Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_seperator2D(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Decision Boundary with Data with Strategic Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_seperator2D(model, a, y, x_lim=(x_low, x_high), z_lim=(z_low, z_high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Other Best Response Definitions\n",
    "Code here allows you to test out what a different best response definitions would look like when applied to a fixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define you Cost\n",
    "from Clf_Learner.costs import COST_DICT\n",
    "\n",
    "target_radius = 2\n",
    "target_eps = (target_radius**2)/4\n",
    "\n",
    "cost_name = \"quadratic\"\n",
    "cost_args = {\"eps\": target_eps}\n",
    "\n",
    "cost = COST_DICT[cost_name]\n",
    "cost = cost(**cost_args)\n",
    "\n",
    "assert dataset is not None\n",
    "cost.set_standardiser(dataset.get_standardiser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clf_Learner.utilities import UTILITY_DICT\n",
    "\n",
    "utility_name = \"strategic\"\n",
    "utility_args = {\"margin\": 0.01}\n",
    "\n",
    "utility = UTILITY_DICT[utility_name]\n",
    "utility = utility(**utility_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from Clf_Learner.best_reponses import BR_DICT\n",
    "\n",
    "best_response_name = \"lagrange\"\n",
    "br_args = {\"max_iterations\": 12000, \"lr\":0.0003, \"margin\": 5e-2, \"lagrange_mult_lr\": 5e-4, \"lagrange_mult_cost_lr\": 5e-2}\n",
    "\n",
    "best_response = BR_DICT[best_response_name]\n",
    "best_response = best_response(cost=cost, utility=utility, **br_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = best_response(X, model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_high, z_high = torch.max(X,0).values.tolist()\n",
    "x_low, z_low = torch.min(X,0).values.tolist()\n",
    "\n",
    "visualize_seperator2D(model, X, y)\n",
    "visualize_seperator2D(model, br, y, x_lim=(x_low, x_high), z_lim=(z_low, z_high), animate=False, store=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
